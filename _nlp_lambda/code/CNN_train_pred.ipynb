{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "# from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from unidecode import unidecode_expect_nonascii, unidecode\n",
    "client = MongoClient(connect=False)\n",
    "db = client['newscraper']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_schema(table='articles_cleaned'):\n",
    "    from pprint import pprint\n",
    "    pprint(next(db[table].find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a2730f35cedcc6022e9026e'),\n",
      " 'flags': ['left-center', 'very high'],\n",
      " 'source': 'https://brookings.edu',\n",
      " 'text': 'A chronicle of the year that changed Soviet Russia—and molded the '\n",
      "         'future path of one of America’s pre-eminent diplomatic '\n",
      "         'correspondents\\n'\n",
      "         '\\n'\n",
      "         '1956 was an extraordinary year in modern Russian history. It was '\n",
      "         'called “the year of the thaw”—a time when Stalin’s dark legacy of '\n",
      "         'dictatorship died in February only to be reborn later that December. '\n",
      "         'This historic arc from rising hope to crushing despair opened with a '\n",
      "         'speech by Nikita Khrushchev, then the unpredictable leader of the '\n",
      "         'Soviet Union. He astounded everyone by denouncing the one figure '\n",
      "         'who, up to that time, had been hailed as a “genius,” a wizard of '\n",
      "         'communism—Josef Stalin himself. Now, suddenly, this once '\n",
      "         'unassailable god was being portrayed as a “madman” whose '\n",
      "         'idiosyncratic rule had seriously undermined communism and endangered '\n",
      "         'the Soviet state.\\n'\n",
      "         '\\n'\n",
      "         'This amazing switch from hero to villain lifted a heavy overcoat of '\n",
      "         'fear from the backs of ordinary Russians. It also quickly led to '\n",
      "         'anti-communist uprisings in Eastern Europe, none more bloody and '\n",
      "         'challenging than the one in Hungary, which Soviet troops crushed at '\n",
      "         'year’s end.\\n'\n",
      "         '\\n'\n",
      "         'Marvin Kalb, then a young diplomatic attaché at the U.S. Embassy in '\n",
      "         'Moscow, observed this tumultuous year that foretold the end of '\n",
      "         'Soviet communism three decades later. Fluent in Russian, a doctoral '\n",
      "         'candidate at Harvard, he went where few other foreigners would dare '\n",
      "         'go, listening to Russian students secretly attack communism and '\n",
      "         'threaten rebellion against the Soviet system, traveling from one end '\n",
      "         'of a changing country to the other and, thanks to his diplomatic '\n",
      "         'position, meeting and talking with Khrushchev, who playfully '\n",
      "         'nicknamed him Peter the Great.\\n'\n",
      "         '\\n'\n",
      "         'In this, his fifteenth book, Kalb writes a fascinating eyewitness '\n",
      "         'account of a superpower in upheaval and of a people yearning for an '\n",
      "         'end to dictatorship.',\n",
      " 'title': 'The Year I Was Peter the Great',\n",
      " 'url': 'https://www.brookings.edu/book/the-year-i-was-peter-the-great/'}\n"
     ]
    }
   ],
   "source": [
    "show_schema('articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "class Corpus:\n",
    "    ''' Retrieves data from MongoDB'''\n",
    "\n",
    "    def __init__(self, db_table='articles', field='text', n_words=20000):\n",
    "\n",
    "        self.n_words = n_words\n",
    "        self.field = field\n",
    "        self.db_table = db_table\n",
    "        self.labels = [\n",
    "            'center', 'conspiracy', 'extreme left', 'extreme right',\n",
    "            'fake news', 'hate', 'high', 'left', 'left-center', 'low', 'mixed',\n",
    "            'pro-science', 'propaganda', 'right', 'right-center', 'satire',\n",
    "            'very high'\n",
    "        ]\n",
    "\n",
    "    def get_all_rows(self):\n",
    "        ''' Retrieve target table from db '''\n",
    "        print(self.n_words)\n",
    "        self.articles = [_ for _ in db[self.db_table].find() if _[self.field]]\n",
    "        self.n_articles = len(self.articles)\n",
    "\n",
    "from keras.preprocessing import text as Text\n",
    "class KerasVectorizer(Corpus):\n",
    "    ''' Performs vectorization and text preprocessing '''\n",
    "    \n",
    "    \n",
    "    def __init__(self, dnn_type='seq', max_len=1000, predict_str=False):\n",
    "        super().__init__()\n",
    "        if not predict_str:\n",
    "            self.get_all_rows()\n",
    "            self.train = True\n",
    "        else:\n",
    "            self.articles = predict_str\n",
    "            self.train = False\n",
    "        self.dnn_type = dnn_type\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def clean(self, seq):\n",
    "        if len(seq):\n",
    "            seq = unidecode(seq)\n",
    "            return ' '.join(\n",
    "                Text.text_to_word_sequence(\n",
    "                    seq,\n",
    "                    filters=\n",
    "                    '''1234567890!\"#$%&()*+,-\\n./—:;<=>?@[\\\\]^_`{|}~\\t\\'“”'''))\n",
    "\n",
    "    def fit(self):\n",
    "        ''' Fit vectorizer on corpus '''\n",
    "\n",
    "        Tokenizer = Text.Tokenizer\n",
    "        tokenizer = Tokenizer(self.n_words)\n",
    "\n",
    "        print('cleaning text')\n",
    "        texts = [self.clean(entry[self.field]) for entry in self.articles]\n",
    "        print('fitting vector')\n",
    "        try:\n",
    "            tokenizer = pickle.load(open('vector234.pkl', 'rb'))\n",
    "        except FileNotFoundError:\n",
    "            tokenizer.fit_on_texts(texts)\n",
    "            pickle.dump(tokenizer, open('vector234.pkl', 'wb'))\n",
    "        self.corpus_vector = tokenizer\n",
    "        self.lookup = {\n",
    "            k: v\n",
    "            for k, v in self.corpus_vector.word_index.items()\n",
    "            if v < self.n_words\n",
    "        }\n",
    "\n",
    "        json.dump(self.lookup, open('lookup234.json', 'w'))\n",
    "\n",
    "    def gen_x_onehot(self):\n",
    "        if self.train:\n",
    "            text = [self.clean(_[self.field]) for _ in self.articles]\n",
    "        else:\n",
    "            text = self.articles\n",
    "        for entry in text:\n",
    "            entry = keras.preprocessing.text.text_to_word_sequence(entry)\n",
    "            yield [self.lookup[word] for word in entry if word in self.lookup]\n",
    "\n",
    "    def transform_x_onehot(self):\n",
    "        x = list(self.gen_x_onehot())\n",
    "        #         v_len = max([len(_)for _ in x])\n",
    "        #         print ('longest text', v_len)\n",
    "        #         if v_len > self.max_len:\n",
    "        #             v_len = self.max_len\n",
    "        self.rev_lookup = {v: k for k, v in self.lookup.items()}\n",
    "        v_len = self.max_len\n",
    "        print('using limit of', v_len)\n",
    "        self.lens = []\n",
    "        for entry in x:\n",
    "            self.lens.append(len(entry))\n",
    "\n",
    "            if len(entry) >= v_len:\n",
    "                yield np.array(entry[-v_len:])\n",
    "            else:\n",
    "                yield np.array([0 for _ in range(v_len - len(entry))] + entry)\n",
    "\n",
    "    def transform_y(self):\n",
    "        ''' Vectorizes y labels '''\n",
    "        for entry in self.articles:\n",
    "            yield np.array(\n",
    "                [1 if _ in entry['flags'] else 0 for _ in self.labels])\n",
    "\n",
    "    def transform_x(self):\n",
    "        ''' Transforms texts to the vector '''\n",
    "        vector = pickle.load(open('./vector234.pkl', 'rb'))\n",
    "\n",
    "        self.lookup = json.load(open('lookup234.json'))\n",
    "\n",
    "        return list(self.transform_x_onehot())\n",
    "\n",
    "    def x_y(self):\n",
    "        self.fit()\n",
    "        print('producing x, y data')\n",
    "        y = list(self.transform_y())\n",
    "\n",
    "        if self.dnn_type == 'seq':\n",
    "            x = list(self.transform_x_onehot())\n",
    "        elif self.dnn_type == 'bow':\n",
    "            x = self.transform_x()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def prep_data():\n",
    "    k_v = KerasVectorizer(max_len=1000)\n",
    "    #http://www.newswhip.com/2013/12/article-length/\n",
    "    x, y = k_v.x_y()\n",
    "    print('data prepared')\n",
    "    print(x[0].shape)\n",
    "\n",
    "    return k_v, x, y\n",
    "\n",
    "\n",
    "def predict_data(text):\n",
    "    k_v = KerasVectorizer(max_len=1000, predict_str=[text])\n",
    "\n",
    "    x = k_v.transform_x()\n",
    "    print('data prepared')\n",
    "    print(x[0].shape)\n",
    "\n",
    "    return k_v, x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%%time\n",
    "# k_vp, xp = predict_data(text)\n",
    "\n",
    "# print(xp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickles loaded\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "\n",
    "def train_setup():\n",
    "    k_v, X, Y = prep_data()\n",
    "\n",
    "    def val_set(x, y):\n",
    "        val_size = .15\n",
    "        val_ind = int(len(x) * val_size)\n",
    "        print(val_ind, len(x))\n",
    "\n",
    "        randomize = np.arange(len(x))\n",
    "        np.random.shuffle(randomize)\n",
    "\n",
    "        x = np.array(x)[randomize]\n",
    "        y = np.array(y)[randomize]\n",
    "\n",
    "        x = x[:-val_ind]\n",
    "        y = y[:-val_ind]\n",
    "        x_val = x[-val_ind:]\n",
    "        y_val = y[-val_ind:]\n",
    "        assert len(y) == len(x)\n",
    "\n",
    "        return x, y, x_val, y_val\n",
    "\n",
    "    x, y, x_val, y_val = val_set(X, Y)\n",
    "    return x, y, x_val, y_val, k_v\n",
    "\n",
    "\n",
    "def load_pickles():\n",
    "    pickle_rick = 'x', 'y', 'x_val', 'y_val', 'k_v'\n",
    "\n",
    "    for rick in pickle_rick:\n",
    "        yield pickle.load(open(rick + '.pkl', 'rb'))\n",
    "\n",
    "\n",
    "def save_pickles():\n",
    "    x, y, x_val, y_val, k_v = train_setup()\n",
    "    print('saving pickles')\n",
    "    pickle_rick = {'x': x, 'y': y, 'x_val': x_val, 'y_val': y_val, 'k_v': k_v}\n",
    "    for k, v in pickle_rick.items():\n",
    "        yield pickle.dump(v, open(k + '.pkl', 'wb'))\n",
    "\n",
    "\n",
    "try:\n",
    "    x, y, x_val, y_val, k_v = list(load_pickles())\n",
    "    print('pickles loaded')\n",
    "except Exception as e:\n",
    "\n",
    "    #     x, y, x_val, y_val, k_v = train_setup()\n",
    "    list(save_pickles())\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, len(x))\n",
    "print(i)\n",
    "print(x[i])\n",
    "#print([k_v.labels[n] for n,v in enumerate(y[i]) if v >0])\n",
    "for word in x[i]:\n",
    "    if word:\n",
    "        print(k_v.rev_lookup[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 25266 samples, validate on 4458 samples\n",
      "Epoch 1/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8271Epoch 00001: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.5833 - acc: 0.8271 - val_loss: 0.3593 - val_acc: 0.8700\n",
      "\n",
      "Epoch 2/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.3651 - acc: 0.8665Epoch 00002: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.3651 - acc: 0.8665 - val_loss: 0.3183 - val_acc: 0.8780\n",
      "\n",
      "Epoch 3/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.3262 - acc: 0.8776Epoch 00003: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.3261 - acc: 0.8776 - val_loss: 0.2899 - val_acc: 0.8886\n",
      "\n",
      "Epoch 4/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.3010 - acc: 0.8859Epoch 00004: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.3009 - acc: 0.8859 - val_loss: 0.2656 - val_acc: 0.8970\n",
      "\n",
      "Epoch 5/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.8926Epoch 00005: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2820 - acc: 0.8926 - val_loss: 0.2473 - val_acc: 0.9033\n",
      "\n",
      "Epoch 6/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.8985Epoch 00006: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2647 - acc: 0.8985 - val_loss: 0.2328 - val_acc: 0.9089\n",
      "\n",
      "Epoch 7/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9030Epoch 00007: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2515 - acc: 0.9030 - val_loss: 0.2196 - val_acc: 0.9135\n",
      "\n",
      "Epoch 8/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9074Epoch 00008: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2406 - acc: 0.9074 - val_loss: 0.2056 - val_acc: 0.9192\n",
      "\n",
      "Epoch 9/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9115Epoch 00009: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2290 - acc: 0.9114 - val_loss: 0.1954 - val_acc: 0.9239\n",
      "\n",
      "Epoch 10/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9144Epoch 00010: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2210 - acc: 0.9144 - val_loss: 0.1888 - val_acc: 0.9266\n",
      "\n",
      "Epoch 11/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9176Epoch 00011: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2130 - acc: 0.9176 - val_loss: 0.1793 - val_acc: 0.9294\n",
      "\n",
      "Epoch 12/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9205Epoch 00012: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.2048 - acc: 0.9205 - val_loss: 0.1706 - val_acc: 0.9336\n",
      "\n",
      "Epoch 13/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9235Epoch 00013: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1977 - acc: 0.9235 - val_loss: 0.1622 - val_acc: 0.9364\n",
      "\n",
      "Epoch 14/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1918 - acc: 0.9257Epoch 00014: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1917 - acc: 0.9258 - val_loss: 0.1551 - val_acc: 0.9403\n",
      "\n",
      "Epoch 15/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9282Epoch 00015: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1857 - acc: 0.9282 - val_loss: 0.1493 - val_acc: 0.9418\n",
      "\n",
      "Epoch 16/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9301Epoch 00016: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1808 - acc: 0.9301 - val_loss: 0.1430 - val_acc: 0.9454\n",
      "\n",
      "Epoch 17/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9316Epoch 00017: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1765 - acc: 0.9315 - val_loss: 0.1402 - val_acc: 0.9455\n",
      "\n",
      "Epoch 18/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9330Epoch 00018: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1718 - acc: 0.9330 - val_loss: 0.1348 - val_acc: 0.9481\n",
      "\n",
      "Epoch 19/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1671 - acc: 0.9350Epoch 00019: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1672 - acc: 0.9350 - val_loss: 0.1291 - val_acc: 0.9510\n",
      "\n",
      "Epoch 20/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9368Epoch 00020: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1625 - acc: 0.9368 - val_loss: 0.1254 - val_acc: 0.9519\n",
      "\n",
      "Epoch 21/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9383Epoch 00021: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1597 - acc: 0.9383 - val_loss: 0.1212 - val_acc: 0.9534\n",
      "\n",
      "Epoch 22/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9397Epoch 00022: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1559 - acc: 0.9397 - val_loss: 0.1193 - val_acc: 0.9541\n",
      "\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9408Epoch 00023: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1530 - acc: 0.9408 - val_loss: 0.1152 - val_acc: 0.9570\n",
      "\n",
      "Epoch 24/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9419Epoch 00024: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1495 - acc: 0.9419 - val_loss: 0.1102 - val_acc: 0.9586\n",
      "\n",
      "Epoch 25/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9435Epoch 00025: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1462 - acc: 0.9435 - val_loss: 0.1070 - val_acc: 0.9600\n",
      "\n",
      "Epoch 26/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9451Epoch 00026: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1427 - acc: 0.9451 - val_loss: 0.1058 - val_acc: 0.9598\n",
      "\n",
      "Epoch 27/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9455Epoch 00027: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1413 - acc: 0.9454 - val_loss: 0.1013 - val_acc: 0.9627\n",
      "\n",
      "Epoch 28/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9469Epoch 00028: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1381 - acc: 0.9469 - val_loss: 0.0994 - val_acc: 0.9631\n",
      "\n",
      "Epoch 29/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9474Epoch 00029: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1362 - acc: 0.9474 - val_loss: 0.0969 - val_acc: 0.9647\n",
      "\n",
      "Epoch 30/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9491Epoch 00030: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1330 - acc: 0.9491 - val_loss: 0.0933 - val_acc: 0.9656\n",
      "\n",
      "Epoch 31/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9493Epoch 00031: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1316 - acc: 0.9493 - val_loss: 0.0940 - val_acc: 0.9651\n",
      "\n",
      "Epoch 32/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9502Epoch 00032: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1289 - acc: 0.9502 - val_loss: 0.0907 - val_acc: 0.9662\n",
      "\n",
      "Epoch 33/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9512Epoch 00033: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1266 - acc: 0.9513 - val_loss: 0.0884 - val_acc: 0.9678\n",
      "\n",
      "Epoch 34/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9518Epoch 00034: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1247 - acc: 0.9518 - val_loss: 0.0860 - val_acc: 0.9684\n",
      "\n",
      "Epoch 35/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9526Epoch 00035: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1230 - acc: 0.9526 - val_loss: 0.0849 - val_acc: 0.9689\n",
      "\n",
      "Epoch 36/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9535Epoch 00036: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1208 - acc: 0.9535 - val_loss: 0.0836 - val_acc: 0.9690\n",
      "\n",
      "Epoch 37/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9541Epoch 00037: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1197 - acc: 0.9541 - val_loss: 0.0824 - val_acc: 0.9689\n",
      "\n",
      "Epoch 38/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9550Epoch 00038: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1176 - acc: 0.9550 - val_loss: 0.0789 - val_acc: 0.9727\n",
      "\n",
      "Epoch 39/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9553Epoch 00039: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1168 - acc: 0.9552 - val_loss: 0.0778 - val_acc: 0.9718\n",
      "\n",
      "Epoch 40/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9560Epoch 00040: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1152 - acc: 0.9560 - val_loss: 0.0772 - val_acc: 0.9725\n",
      "\n",
      "Epoch 41/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9565Epoch 00041: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1137 - acc: 0.9565 - val_loss: 0.0741 - val_acc: 0.9735\n",
      "\n",
      "Epoch 42/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9569Epoch 00042: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1127 - acc: 0.9569 - val_loss: 0.0736 - val_acc: 0.9735\n",
      "\n",
      "Epoch 43/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9583Epoch 00043: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1099 - acc: 0.9582 - val_loss: 0.0712 - val_acc: 0.9745\n",
      "\n",
      "Epoch 44/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9585Epoch 00044: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1086 - acc: 0.9585 - val_loss: 0.0705 - val_acc: 0.9747\n",
      "\n",
      "Epoch 45/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9585Epoch 00045: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1089 - acc: 0.9585 - val_loss: 0.0693 - val_acc: 0.9753\n",
      "\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9594Epoch 00046: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1064 - acc: 0.9595 - val_loss: 0.0688 - val_acc: 0.9750\n",
      "\n",
      "Epoch 47/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9596Epoch 00047: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1058 - acc: 0.9596 - val_loss: 0.0669 - val_acc: 0.9760\n",
      "\n",
      "Epoch 48/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9602Epoch 00048: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1046 - acc: 0.9602 - val_loss: 0.0656 - val_acc: 0.9767\n",
      "\n",
      "Epoch 49/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9608Epoch 00049: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1026 - acc: 0.9608 - val_loss: 0.0652 - val_acc: 0.9769\n",
      "\n",
      "Epoch 50/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9615Epoch 00050: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1012 - acc: 0.9615 - val_loss: 0.0635 - val_acc: 0.9775\n",
      "\n",
      "Epoch 51/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9619Epoch 00051: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.1004 - acc: 0.9619 - val_loss: 0.0632 - val_acc: 0.9770\n",
      "\n",
      "Epoch 52/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9623Epoch 00052: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0996 - acc: 0.9623 - val_loss: 0.0614 - val_acc: 0.9789\n",
      "\n",
      "Epoch 53/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9626Epoch 00053: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0992 - acc: 0.9626 - val_loss: 0.0619 - val_acc: 0.9776\n",
      "\n",
      "Epoch 54/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9625Epoch 00054: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0977 - acc: 0.9625 - val_loss: 0.0600 - val_acc: 0.9791\n",
      "\n",
      "Epoch 55/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9628Epoch 00055: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0971 - acc: 0.9628 - val_loss: 0.0591 - val_acc: 0.9792\n",
      "\n",
      "Epoch 56/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9640Epoch 00056: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0954 - acc: 0.9640 - val_loss: 0.0589 - val_acc: 0.9793\n",
      "\n",
      "Epoch 57/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9641Epoch 00057: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0945 - acc: 0.9641 - val_loss: 0.0579 - val_acc: 0.9792\n",
      "\n",
      "Epoch 58/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9641Epoch 00058: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0949 - acc: 0.9641 - val_loss: 0.0575 - val_acc: 0.9794\n",
      "\n",
      "Epoch 59/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9642Epoch 00059: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0946 - acc: 0.9642 - val_loss: 0.0564 - val_acc: 0.9803\n",
      "\n",
      "Epoch 60/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9648Epoch 00060: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0928 - acc: 0.9648 - val_loss: 0.0565 - val_acc: 0.9798\n",
      "\n",
      "Epoch 61/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9650Epoch 00061: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0926 - acc: 0.9650 - val_loss: 0.0549 - val_acc: 0.9806\n",
      "\n",
      "Epoch 62/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9655Epoch 00062: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0919 - acc: 0.9655 - val_loss: 0.0538 - val_acc: 0.9809\n",
      "\n",
      "Epoch 63/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9661Epoch 00063: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0894 - acc: 0.9661 - val_loss: 0.0548 - val_acc: 0.9802\n",
      "\n",
      "Epoch 64/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9664Epoch 00064: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0895 - acc: 0.9664 - val_loss: 0.0525 - val_acc: 0.9815\n",
      "\n",
      "Epoch 65/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9663Epoch 00065: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0893 - acc: 0.9663 - val_loss: 0.0527 - val_acc: 0.9816\n",
      "\n",
      "Epoch 66/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9669Epoch 00066: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0880 - acc: 0.9669 - val_loss: 0.0514 - val_acc: 0.9822\n",
      "\n",
      "Epoch 67/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9668Epoch 00067: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0876 - acc: 0.9668 - val_loss: 0.0514 - val_acc: 0.9820\n",
      "\n",
      "Epoch 68/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9671Epoch 00068: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0878 - acc: 0.9672 - val_loss: 0.0504 - val_acc: 0.9827\n",
      "\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9678Epoch 00069: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0863 - acc: 0.9677 - val_loss: 0.0496 - val_acc: 0.9826\n",
      "\n",
      "Epoch 70/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9674Epoch 00070: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0862 - acc: 0.9674 - val_loss: 0.0499 - val_acc: 0.9828\n",
      "\n",
      "Epoch 71/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9683Epoch 00071: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0845 - acc: 0.9683 - val_loss: 0.0493 - val_acc: 0.9828\n",
      "\n",
      "Epoch 72/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9686Epoch 00072: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0838 - acc: 0.9686 - val_loss: 0.0487 - val_acc: 0.9830\n",
      "\n",
      "Epoch 73/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9687Epoch 00073: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0843 - acc: 0.9687 - val_loss: 0.0485 - val_acc: 0.9834\n",
      "\n",
      "Epoch 74/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9688Epoch 00074: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0832 - acc: 0.9688 - val_loss: 0.0467 - val_acc: 0.9836\n",
      "\n",
      "Epoch 75/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9694Epoch 00075: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0818 - acc: 0.9693 - val_loss: 0.0471 - val_acc: 0.9837\n",
      "\n",
      "Epoch 76/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9695Epoch 00076: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0818 - acc: 0.9695 - val_loss: 0.0467 - val_acc: 0.9835\n",
      "\n",
      "Epoch 77/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9697Epoch 00077: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0806 - acc: 0.9697 - val_loss: 0.0467 - val_acc: 0.9834\n",
      "\n",
      "Epoch 78/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9698Epoch 00078: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0811 - acc: 0.9698 - val_loss: 0.0460 - val_acc: 0.9843\n",
      "\n",
      "Epoch 79/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9705Epoch 00079: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0796 - acc: 0.9705 - val_loss: 0.0461 - val_acc: 0.9841\n",
      "\n",
      "Epoch 80/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9701Epoch 00080: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0798 - acc: 0.9701 - val_loss: 0.0447 - val_acc: 0.9844\n",
      "\n",
      "Epoch 81/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9702Epoch 00081: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0792 - acc: 0.9702 - val_loss: 0.0458 - val_acc: 0.9838\n",
      "\n",
      "Epoch 82/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9704Epoch 00082: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0798 - acc: 0.9704 - val_loss: 0.0452 - val_acc: 0.9841\n",
      "\n",
      "Epoch 83/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9709Epoch 00083: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0784 - acc: 0.9709 - val_loss: 0.0443 - val_acc: 0.9843\n",
      "\n",
      "Epoch 84/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9713Epoch 00084: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0770 - acc: 0.9713 - val_loss: 0.0444 - val_acc: 0.9850\n",
      "\n",
      "Epoch 85/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9711Epoch 00085: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0775 - acc: 0.9711 - val_loss: 0.0428 - val_acc: 0.9852\n",
      "\n",
      "Epoch 86/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9714Epoch 00086: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0774 - acc: 0.9713 - val_loss: 0.0422 - val_acc: 0.9855\n",
      "\n",
      "Epoch 87/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9714Epoch 00087: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0763 - acc: 0.9714 - val_loss: 0.0420 - val_acc: 0.9855\n",
      "\n",
      "Epoch 88/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9721Epoch 00088: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0763 - acc: 0.9721 - val_loss: 0.0422 - val_acc: 0.9854\n",
      "\n",
      "Epoch 89/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9725Epoch 00089: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0748 - acc: 0.9725 - val_loss: 0.0415 - val_acc: 0.9858\n",
      "\n",
      "Epoch 90/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9723Epoch 00090: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0751 - acc: 0.9723 - val_loss: 0.0412 - val_acc: 0.9857\n",
      "\n",
      "Epoch 91/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9724Epoch 00091: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0746 - acc: 0.9724 - val_loss: 0.0412 - val_acc: 0.9862\n",
      "\n",
      "Epoch 92/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9724Epoch 00092: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0744 - acc: 0.9724 - val_loss: 0.0411 - val_acc: 0.9861\n",
      "\n",
      "Epoch 93/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9731Epoch 00093: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0729 - acc: 0.9731 - val_loss: 0.0396 - val_acc: 0.9870\n",
      "\n",
      "Epoch 94/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9728Epoch 00094: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0733 - acc: 0.9728 - val_loss: 0.0407 - val_acc: 0.9858\n",
      "\n",
      "Epoch 95/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9731Epoch 00095: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0729 - acc: 0.9731 - val_loss: 0.0397 - val_acc: 0.9866\n",
      "\n",
      "Epoch 96/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9729Epoch 00096: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0733 - acc: 0.9729 - val_loss: 0.0394 - val_acc: 0.9867\n",
      "\n",
      "Epoch 97/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9732Epoch 00097: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0725 - acc: 0.9732 - val_loss: 0.0393 - val_acc: 0.9869\n",
      "\n",
      "Epoch 98/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9735Epoch 00098: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0716 - acc: 0.9735 - val_loss: 0.0385 - val_acc: 0.9870\n",
      "\n",
      "Epoch 99/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9736Epoch 00099: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0717 - acc: 0.9736 - val_loss: 0.0391 - val_acc: 0.9864\n",
      "\n",
      "Epoch 100/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9734Epoch 00100: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0722 - acc: 0.9734 - val_loss: 0.0383 - val_acc: 0.9872\n",
      "\n",
      "Epoch 101/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9741Epoch 00101: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0699 - acc: 0.9741 - val_loss: 0.0386 - val_acc: 0.9868\n",
      "\n",
      "Epoch 102/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9740Epoch 00102: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0706 - acc: 0.9740 - val_loss: 0.0384 - val_acc: 0.9867\n",
      "\n",
      "Epoch 103/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9742Epoch 00103: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0699 - acc: 0.9742 - val_loss: 0.0379 - val_acc: 0.9871\n",
      "\n",
      "Epoch 104/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9744Epoch 00104: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0696 - acc: 0.9744 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "\n",
      "Epoch 105/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9745Epoch 00105: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0691 - acc: 0.9745 - val_loss: 0.0376 - val_acc: 0.9866\n",
      "\n",
      "Epoch 106/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9748Epoch 00106: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0686 - acc: 0.9748 - val_loss: 0.0369 - val_acc: 0.9873\n",
      "\n",
      "Epoch 107/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9747Epoch 00107: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0688 - acc: 0.9748 - val_loss: 0.0374 - val_acc: 0.9871\n",
      "\n",
      "Epoch 108/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9747Epoch 00108: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0691 - acc: 0.9747 - val_loss: 0.0362 - val_acc: 0.9878\n",
      "\n",
      "Epoch 109/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9751Epoch 00109: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0676 - acc: 0.9751 - val_loss: 0.0361 - val_acc: 0.9880\n",
      "\n",
      "Epoch 110/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9752Epoch 00110: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0679 - acc: 0.9752 - val_loss: 0.0360 - val_acc: 0.9883\n",
      "\n",
      "Epoch 111/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9752Epoch 00111: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0674 - acc: 0.9752 - val_loss: 0.0361 - val_acc: 0.9882\n",
      "\n",
      "Epoch 112/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9754Epoch 00112: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0676 - acc: 0.9754 - val_loss: 0.0362 - val_acc: 0.9878\n",
      "\n",
      "Epoch 113/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9754Epoch 00113: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0675 - acc: 0.9754 - val_loss: 0.0361 - val_acc: 0.9870\n",
      "\n",
      "Epoch 114/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9757Epoch 00114: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0665 - acc: 0.9757 - val_loss: 0.0361 - val_acc: 0.9872\n",
      "\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9756Epoch 00115: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0665 - acc: 0.9756 - val_loss: 0.0350 - val_acc: 0.9880\n",
      "\n",
      "Epoch 116/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9758Epoch 00116: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0664 - acc: 0.9758 - val_loss: 0.0357 - val_acc: 0.9878\n",
      "\n",
      "Epoch 117/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9760Epoch 00117: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0658 - acc: 0.9760 - val_loss: 0.0348 - val_acc: 0.9880\n",
      "\n",
      "Epoch 118/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9761Epoch 00118: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0651 - acc: 0.9761 - val_loss: 0.0349 - val_acc: 0.9883\n",
      "\n",
      "Epoch 119/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9765Epoch 00119: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0644 - acc: 0.9765 - val_loss: 0.0340 - val_acc: 0.9886\n",
      "\n",
      "Epoch 120/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9763Epoch 00120: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0650 - acc: 0.9763 - val_loss: 0.0341 - val_acc: 0.9888\n",
      "\n",
      "Epoch 121/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9764Epoch 00121: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0644 - acc: 0.9764 - val_loss: 0.0336 - val_acc: 0.9889\n",
      "\n",
      "Epoch 122/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9763Epoch 00122: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0651 - acc: 0.9763 - val_loss: 0.0336 - val_acc: 0.9889\n",
      "\n",
      "Epoch 123/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9768Epoch 00123: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0636 - acc: 0.9768 - val_loss: 0.0330 - val_acc: 0.9892\n",
      "\n",
      "Epoch 124/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9767Epoch 00124: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0643 - acc: 0.9767 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "\n",
      "Epoch 125/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9768Epoch 00125: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0637 - acc: 0.9768 - val_loss: 0.0330 - val_acc: 0.9892\n",
      "\n",
      "Epoch 126/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9769Epoch 00126: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0639 - acc: 0.9768 - val_loss: 0.0328 - val_acc: 0.9894\n",
      "\n",
      "Epoch 127/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9769Epoch 00127: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0633 - acc: 0.9769 - val_loss: 0.0336 - val_acc: 0.9889\n",
      "\n",
      "Epoch 128/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9774Epoch 00128: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0625 - acc: 0.9774 - val_loss: 0.0327 - val_acc: 0.9891\n",
      "\n",
      "Epoch 129/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9771Epoch 00129: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0631 - acc: 0.9771 - val_loss: 0.0328 - val_acc: 0.9889\n",
      "\n",
      "Epoch 130/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9772Epoch 00130: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0629 - acc: 0.9771 - val_loss: 0.0324 - val_acc: 0.9892\n",
      "\n",
      "Epoch 131/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9775Epoch 00131: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0619 - acc: 0.9775 - val_loss: 0.0319 - val_acc: 0.9894\n",
      "\n",
      "Epoch 132/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9773Epoch 00132: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0627 - acc: 0.9773 - val_loss: 0.0324 - val_acc: 0.9895\n",
      "\n",
      "Epoch 133/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9778Epoch 00133: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0616 - acc: 0.9778 - val_loss: 0.0323 - val_acc: 0.9890\n",
      "\n",
      "Epoch 134/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9777Epoch 00134: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0616 - acc: 0.9777 - val_loss: 0.0320 - val_acc: 0.9894\n",
      "\n",
      "Epoch 135/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9781Epoch 00135: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0612 - acc: 0.9781 - val_loss: 0.0311 - val_acc: 0.9899\n",
      "\n",
      "Epoch 136/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9781Epoch 00136: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0606 - acc: 0.9781 - val_loss: 0.0316 - val_acc: 0.9896\n",
      "\n",
      "Epoch 137/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9779Epoch 00137: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0610 - acc: 0.9779 - val_loss: 0.0312 - val_acc: 0.9898\n",
      "\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9782Epoch 00138: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0596 - acc: 0.9782 - val_loss: 0.0309 - val_acc: 0.9895\n",
      "\n",
      "Epoch 139/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9779Epoch 00139: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0604 - acc: 0.9779 - val_loss: 0.0311 - val_acc: 0.9898\n",
      "\n",
      "Epoch 140/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9779Epoch 00140: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0614 - acc: 0.9779 - val_loss: 0.0313 - val_acc: 0.9901\n",
      "\n",
      "Epoch 141/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9780Epoch 00141: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0606 - acc: 0.9780 - val_loss: 0.0305 - val_acc: 0.9898\n",
      "\n",
      "Epoch 142/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9783Epoch 00142: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0600 - acc: 0.9783 - val_loss: 0.0307 - val_acc: 0.9899\n",
      "\n",
      "Epoch 143/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9784Epoch 00143: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0598 - acc: 0.9784 - val_loss: 0.0313 - val_acc: 0.9892\n",
      "\n",
      "Epoch 144/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9786Epoch 00144: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0596 - acc: 0.9786 - val_loss: 0.0306 - val_acc: 0.9895\n",
      "\n",
      "Epoch 145/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9786Epoch 00145: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0595 - acc: 0.9786 - val_loss: 0.0303 - val_acc: 0.9899\n",
      "\n",
      "Epoch 146/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9788Epoch 00146: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0586 - acc: 0.9788 - val_loss: 0.0305 - val_acc: 0.9895\n",
      "\n",
      "Epoch 147/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9785Epoch 00147: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0593 - acc: 0.9785 - val_loss: 0.0294 - val_acc: 0.9902\n",
      "\n",
      "Epoch 148/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9790Epoch 00148: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0589 - acc: 0.9790 - val_loss: 0.0297 - val_acc: 0.9899\n",
      "\n",
      "Epoch 149/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9788Epoch 00149: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0588 - acc: 0.9788 - val_loss: 0.0297 - val_acc: 0.9903\n",
      "\n",
      "Epoch 150/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9791Epoch 00150: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0584 - acc: 0.9791 - val_loss: 0.0290 - val_acc: 0.9903\n",
      "\n",
      "Epoch 151/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9791Epoch 00151: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0582 - acc: 0.9791 - val_loss: 0.0294 - val_acc: 0.9902\n",
      "\n",
      "Epoch 152/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9789Epoch 00152: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0581 - acc: 0.9789 - val_loss: 0.0296 - val_acc: 0.9903\n",
      "\n",
      "Epoch 153/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9793Epoch 00153: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0577 - acc: 0.9793 - val_loss: 0.0295 - val_acc: 0.9901\n",
      "\n",
      "Epoch 154/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9794Epoch 00154: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0576 - acc: 0.9794 - val_loss: 0.0285 - val_acc: 0.9908\n",
      "\n",
      "Epoch 155/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9796Epoch 00155: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0570 - acc: 0.9796 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "\n",
      "Epoch 156/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9792Epoch 00156: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0576 - acc: 0.9792 - val_loss: 0.0292 - val_acc: 0.9901\n",
      "\n",
      "Epoch 157/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9793Epoch 00157: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0577 - acc: 0.9792 - val_loss: 0.0290 - val_acc: 0.9905\n",
      "\n",
      "Epoch 158/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9793Epoch 00158: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0576 - acc: 0.9793 - val_loss: 0.0289 - val_acc: 0.9901\n",
      "\n",
      "Epoch 159/1000\n",
      "25248/25266 [============================>.]25248/25266 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9796Epoch 00159: saving model to tester.h5\n",
      "25266/25266 [==============================]25266/25266 [==============================] - 70s 3ms/step - loss: 0.0570 - acc: 0.9796 - val_loss: 0.0286 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00159: early stopping\n"
     ]
    }
   ],
   "source": [
    "def dnn():\n",
    "\n",
    "    Sequential = keras.models.Sequential\n",
    "    load_model = keras.models.load_model\n",
    "    Tokenizer = keras.preprocessing.text.Tokenizer\n",
    "    Activation = keras.layers.Activation\n",
    "    SGD = keras.optimizers.SGD\n",
    "    Adam = keras.optimizers.Adam\n",
    "    BatchNormalization = keras.layers.BatchNormalization\n",
    "    to_categorical = keras.utils.to_categorical\n",
    "    ModelCheckpoint = keras.callbacks.ModelCheckpoint\n",
    "    Embedding = keras.layers.Embedding\n",
    "    Reshape = keras.layers.Reshape\n",
    "    Flatten = keras.layers.Flatten\n",
    "    Dropout = keras.layers.Dropout\n",
    "    Concatenate = keras.layers.Concatenate\n",
    "    Dense = keras.layers.Dense\n",
    "    Model = keras.models.Model\n",
    "    Input = keras.layers.Input\n",
    "    Conv2D = keras.layers.Conv2D\n",
    "    MaxPool2D = keras.layers.MaxPool2D\n",
    "\n",
    "    n_classes = 17\n",
    "\n",
    "    def define_model_rnn():\n",
    "        vector_len = x[0].shape[0]\n",
    "        vocab_size = k_v.n_words\n",
    "        embedding_dim = 10\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            keras.layers.Embedding(\n",
    "                vocab_size, embedding_dim, input_shape=(vector_len, )))\n",
    "        model.add(keras.layers.GRU(3, dropout=0.2, recurrent_dropout=0.2))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(n_classes, ))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        return model\n",
    "\n",
    "    def define_model():\n",
    "        vector_len = k_v.n_words\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, input_shape=(vector_len, )))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(32))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(n_classes, ))\n",
    "        model.add(Activation('sigmoid'))\n",
    "        return model\n",
    "\n",
    "    def define_model_cnn():\n",
    "\n",
    "        sequence_length = x.shape[1]\n",
    "        vocabulary_size = k_v.n_words\n",
    "        embedding_dim = 5\n",
    "#         filter_sizes = [2, 3, 4]\n",
    "        filter_sizes = [2, 3]\n",
    "        num_filters = 512\n",
    "        drop = 0.5\n",
    "\n",
    "        epochs = 100\n",
    "        batch_size = 30\n",
    "\n",
    "        inputs = Input(shape=(sequence_length, ), dtype='int32')\n",
    "        embedding = Embedding(\n",
    "            input_dim=vocabulary_size,\n",
    "            output_dim=embedding_dim,\n",
    "            input_length=sequence_length)(inputs)\n",
    "        reshape = Reshape((sequence_length, embedding_dim, 1))(embedding)\n",
    "\n",
    "        conv_0 = Conv2D(\n",
    "            num_filters,\n",
    "            kernel_size=(filter_sizes[0], embedding_dim),\n",
    "            padding='valid',\n",
    "            kernel_initializer='normal',\n",
    "            activation='relu')(reshape)\n",
    "        conv_1 = Conv2D(\n",
    "            num_filters,\n",
    "            kernel_size=(filter_sizes[1], embedding_dim),\n",
    "            padding='valid',\n",
    "            kernel_initializer='normal',\n",
    "            activation='relu')(reshape)\n",
    "#         conv_2 = Conv2D(\n",
    "#             num_filters,\n",
    "#             kernel_size=(filter_sizes[2], embedding_dim),\n",
    "#             padding='valid',\n",
    "#             kernel_initializer='normal',\n",
    "#             activation='relu')(reshape)\n",
    "\n",
    "        maxpool_0 = MaxPool2D(\n",
    "            pool_size=(sequence_length - filter_sizes[0] + 1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding='valid')(conv_0)\n",
    "        maxpool_1 = MaxPool2D(\n",
    "            pool_size=(sequence_length - filter_sizes[1] + 1, 1),\n",
    "            strides=(1, 1),\n",
    "            padding='valid')(conv_1)\n",
    "#         maxpool_2 = MaxPool2D(\n",
    "#             pool_size=(sequence_length - filter_sizes[2] + 1, 1),\n",
    "#             strides=(1, 1),\n",
    "#             padding='valid')(conv_2)\n",
    "\n",
    "        concatenated_tensor = Concatenate(axis=1)(\n",
    "            [maxpool_0, maxpool_1])#, maxpool_2])\n",
    "        flatten = Flatten()(concatenated_tensor)\n",
    "        dropout = Dropout(drop)(flatten)\n",
    "        output = Dense(units=n_classes, activation='sigmoid')(dropout)\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "        return model\n",
    "\n",
    "    label_dict = {k: i for i, k in enumerate(k_v.labels)}\n",
    "\n",
    "    print('starting training')\n",
    "\n",
    "    def train():\n",
    "        model = define_model_cnn()\n",
    "#         print(model.summary())\n",
    "#         return\n",
    "\n",
    "        #         model = load_model('CNN20k234.h5')\n",
    "\n",
    "        embedding_layer_names = set(\n",
    "            layer.name for layer in model.layers\n",
    "            if layer.name.startswith('embedding_') or layer.name.startswith('dense_'))\n",
    "\n",
    "#         tb = keras.callbacks.TensorBoard(\n",
    "#             histogram_freq=0,\n",
    "#             batch_size=30,\n",
    "#             log_dir='./logs/test',\n",
    "#             write_graph=False,\n",
    "#             write_grads=False,\n",
    "#             write_images=False,\n",
    "#             embeddings_freq = 1,\n",
    "#             embeddings_layer_names=embedding_layer_names,\n",
    "#             embeddings_metadata='metadata.tsv')\n",
    "\n",
    "        lr1 = Adam(lr=0.00005)\n",
    "        lr2 = Adam(lr=0.0001)\n",
    "        adam = Adam(lr=0.001)\n",
    "        early_stop = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0,\n",
    "            patience=5,\n",
    "            verbose=1,\n",
    "            mode='auto')\n",
    "        checkpointer = ModelCheckpoint(\n",
    "            filepath='tester.h5', verbose=1, save_best_only=False)\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "        history = model.fit(\n",
    "            np.array(x),\n",
    "            np.array(y),\n",
    "            epochs=1000,\n",
    "            verbose=1,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[\n",
    "#                 tb,\n",
    "                #                                 keras.callbacks.TensorBoard(log_dir='./logs/CNN234', write_graph=False),\n",
    "                early_stop,\n",
    "                checkpointer,\n",
    "            ])\n",
    "\n",
    "    train()\n",
    "\n",
    "\n",
    "dnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "load_model = keras.models.load_model\n",
    "model = load_model('tester.h5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_dict = {i: k for i, k in enumerate(k_v.labels)}\n",
    "\n",
    "preds = [model.predict(np.array(text).reshape(1,-1)) for text in x_val[:10]]\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "preds\n",
    "pred_dict = {\n",
    "    label_dict[i]: round(float(p), 6) for i, p in enumerate([_ for _ in preds[0].flatten()])\n",
    "}\n",
    "\n",
    "\n",
    "final_output = [    {\n",
    "    label_dict[i]: round(float(p), 6) for i, p in enumerate([_ for _ in pred.flatten()])\n",
    "} for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for i in range(15):\n",
    "    t = [\n",
    "        _[0] for _ in sorted(\n",
    "            final_output[i].items(), key=lambda kv: kv[1], reverse=True)[:1]\n",
    "    ]\n",
    "\n",
    "    p = [k_v.labels[j] for j in [k for k, _ in enumerate(y_val[i]) if _ > 0]]\n",
    "    print(t, '\\t', p,len(set(p) & set(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "res = pd.DataFrame(final_output,y_val[:10])\n",
    "res.transpose().plot(kind='barh');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def metadata():\n",
    "    with open('./logs/test/metadata.tsv','w') as meta:\n",
    "        meta.write('word\\tvalue\\n')\n",
    "        \n",
    "        meta.write('NULL\\tNULL\\n')\n",
    "        for k, v in sorted(k_v.lookup.items(),key=lambda kv: kv[1]):\n",
    "            meta.write(k+'\\t'+str(v)+'\\n')\n",
    "        \n",
    "    with open('./logs/test/metadata.tsv') as meta_read:\n",
    "        print(len([_ for _ in meta_read.readlines()]))\n",
    "#         print(meta_read.read()[:100])\n",
    "        return\n",
    "        \n",
    "\n",
    "        \n",
    "def labels():\n",
    "    with open('./logs/test/metadata_labels.tsv','w') as meta:\n",
    "        meta.write('label\\tnumber\\n')\n",
    "        for k, v in enumerate(k_v.labels):\n",
    "            \n",
    "            \n",
    "            meta.write(str(k)+'\\t'+str(v))\n",
    "                \n",
    "            meta.write('\\n')\n",
    "                    \n",
    "            \n",
    "        \n",
    "    with open('./logs/test/metadata_labels.tsv') as meta_read:\n",
    "        print(meta_read.read())\n",
    "#         print(len([_ for _ in meta_read.readlines()]))\n",
    "        \n",
    "        return\n",
    "metadata()\n",
    "# labels()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize():\n",
    "    rank = (_ for _ in k_v.lookup.items())\n",
    "    [next(rank) for _ in range(18999)]\n",
    "    pprint([next(rank) for _ in range(1000)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
